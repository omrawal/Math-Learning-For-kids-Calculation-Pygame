{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "300/300 - 12s - loss: 0.5147 - accuracy: 0.8569 - val_loss: 0.1502 - val_accuracy: 0.9530\n",
      "Epoch 2/12\n",
      "300/300 - 12s - loss: 0.1320 - accuracy: 0.9609 - val_loss: 0.0903 - val_accuracy: 0.9732\n",
      "Epoch 3/12\n",
      "300/300 - 12s - loss: 0.0917 - accuracy: 0.9726 - val_loss: 0.0644 - val_accuracy: 0.9804\n",
      "Epoch 4/12\n",
      "300/300 - 12s - loss: 0.0729 - accuracy: 0.9783 - val_loss: 0.0607 - val_accuracy: 0.9804\n",
      "Epoch 5/12\n",
      "300/300 - 12s - loss: 0.0612 - accuracy: 0.9816 - val_loss: 0.0548 - val_accuracy: 0.9817\n",
      "Epoch 6/12\n",
      "300/300 - 12s - loss: 0.0542 - accuracy: 0.9836 - val_loss: 0.0451 - val_accuracy: 0.9860\n",
      "Epoch 7/12\n",
      "300/300 - 12s - loss: 0.0473 - accuracy: 0.9857 - val_loss: 0.0482 - val_accuracy: 0.9853\n",
      "Epoch 8/12\n",
      "300/300 - 12s - loss: 0.0414 - accuracy: 0.9876 - val_loss: 0.0447 - val_accuracy: 0.9848\n",
      "Epoch 9/12\n",
      "300/300 - 12s - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0398 - val_accuracy: 0.9871\n",
      "Epoch 10/12\n",
      "300/300 - 12s - loss: 0.0351 - accuracy: 0.9895 - val_loss: 0.0496 - val_accuracy: 0.9823\n",
      "Epoch 11/12\n",
      "300/300 - 12s - loss: 0.0338 - accuracy: 0.9890 - val_loss: 0.0422 - val_accuracy: 0.9856\n",
      "Epoch 12/12\n",
      "300/300 - 13s - loss: 0.0300 - accuracy: 0.9905 - val_loss: 0.0357 - val_accuracy: 0.9896\n",
      "Accuracy: 0.9896000027656555 \n",
      " Error: 1.0399997234344482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.convolutional import Conv2D \n",
    "from keras.layers.convolutional import MaxPooling2D \n",
    "from keras.layers import Flatten \n",
    "from keras.datasets import mnist\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "X_train = X_train / 255 \n",
    "X_test = X_test / 255 \n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1] \n",
    "\n",
    "def convolutional_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = convolutional_model()\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=12, batch_size=200, verbose=2)\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))\n",
    "model.save('my_mnist_model.h5')\n",
    "#Custom Image Prediction\n",
    "size = 28,28\n",
    "image1=\"test.jpg\"\n",
    "im = Image.open(image1)\n",
    "im_resized = im.resize(size, Image.ANTIALIAS)\n",
    "im_resized.save(\"down.png\",\"PNG\")\n",
    "    \n",
    "img = cv2.imread(\"down.png\",0)  \n",
    "img = img / 255 \n",
    "img = np.reshape(img,(1, 28, 28, 1)) \n",
    "model.predict_classes(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# new_model=load_model('my_mnist_model.h5')\n",
    "# size = 28,28\n",
    "# file=\"7.jpg\"\n",
    "# image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "# image = cv2.resize(image, (28, 28))\n",
    "# image = image.astype('float32')\n",
    "# image = image.reshape(1, 28, 28, 1)\n",
    "# image = 255-image\n",
    "# image /= 255\n",
    "# new_model.predict_classes(img)[0]\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('my_mnist_model.h5')\n",
    "\n",
    "def predict(path_image):\n",
    "    data = []\n",
    "    im = cv2.imread(path_image)\n",
    "    im_gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thre = cv2.threshold(im_gray,220,255,cv2.THRESH_BINARY)\n",
    "    im_not = cv2.bitwise_not(thre)\n",
    "    _,contours,hierachy = cv2.findContours(im_not,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        (x,y,w,h) = cv2.boundingRect(cnt)\n",
    "        roi = im_not[y:y+h,x:x+w]\n",
    "        if (roi.shape[0]<28) and (roi.shape[1]<28):\n",
    "            pass\n",
    "        else:\n",
    "            roi_resize = cv2.resize(roi,(22,22),interpolation = cv2.INTER_LINEAR)\n",
    "            roi_padding = np.pad(roi_resize,(3,3),'constant',constant_values=(0,0))\n",
    "            kernel = np.array([[0,1]],np.uint8)\n",
    "            roi_dila = cv2.dilate(roi_padding,kernel)\n",
    "            roi_reshape = roi_dila.reshape((1,28,28,1)).astype(np.float32)/255\n",
    "            predict = model.predict_classes(roi_reshape)\n",
    "            cv2.putText(im,str(int(predict)),(int((x)),int((y))),1,cv2.FONT_HERSHEY_COMPLEX,(0,255,0),1,cv2.LINE_AA)\n",
    "            data.append([x,y,str(int(predict))])\n",
    "    answer_str=[]\n",
    "    for i in data:\n",
    "        answer_str.append(str(i[-1]))\n",
    "    return (''.join(answer_str))\n",
    "a=predict('2.jpg')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit ('python-cvcourse': conda)",
   "language": "python",
   "name": "python36664bitpythoncvcoursecondae73ddb77eb71422fa6780eae7228eb35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
